{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "p7_image_classification_using_BoVW.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python37964bitcv37conda822813815bf14274ad28e4b3cd777506",
      "display_name": "Python 3.7.9 64-bit ('CV3.7': conda)"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sk0eYw8ojrFq"
      },
      "source": [
        "# Laboratory #07 : Image Classification using Bag of Visual Words\n",
        "\n",
        "At the end of this laboratory, you would get familiarized with\n",
        "\n",
        "*   Creating Bag of Visual Words\n",
        "    *   Feature Extraction\n",
        "    *   Codebook construction\n",
        "    *   Classification\n",
        "*   Using pre-trained deep networks for feature extraction\n",
        "\n",
        "**Remember this is a graded exercise.**\n",
        "\n",
        "*   For every plot, make sure you provide appropriate titles, axis labels, legends, wherever applicable.\n",
        "*   Create reusable functions where ever possible, so that the code could be reused at different places.\n",
        "*   Use will have to mount your drive if you need to access images.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aD5-E8PuaQ5P"
      },
      "source": [
        "# Loading necessary libraries (Feel free to add new libraries if you need for any computation)\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from skimage.feature import ORB\n",
        "from skimage.color import rgb2gray\n",
        "from skimage.io import imread\n",
        "from skimage import feature\n",
        "\n",
        "from matplotlib import pyplot as plt"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "def loadImage(imagePath, gray=False):\n",
        "    image = imread(imagePath)\n",
        "    if gray and len(image.shape) > 2:\n",
        "        image_gray = image\n",
        "        image_gray = rgb2gray(image_gray)\n",
        "        return image_gray\n",
        "    return image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ampx9DIJiuGN"
      },
      "source": [
        "## Loading dataset\n",
        "\n",
        "We will use 3 categories from Caltech 101 objects dataset for this experiment. Upload the dataset to the drive and mount it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PRSJP1XbG6-a"
      },
      "source": [
        "# modify the dataset variable with the path from your drive\n",
        "\n",
        "dataset_path = '.'"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EQptvDX5AFem"
      },
      "source": [
        "# creating the list of files and corresponding labels\n",
        "\n",
        "data = []\n",
        "labels = []\n",
        "\n",
        "categories = ['butterfly', 'kangaroo', 'dalmatian']\n",
        "\n",
        "for idx, cat in enumerate(categories):\n",
        "    path = os.path.join(dataset_path, cat)\n",
        "    files_list = os.listdir(path)\n",
        "    for filename in files_list:\n",
        "        data.append(os.path.join(path, filename))\n",
        "        labels.append(idx)\n",
        "\n",
        "labels = np.array(labels)\n",
        "\n",
        "print('Total number of images:', len(data))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of images: 244\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QdA92ENTfKE-"
      },
      "source": [
        "ncl = len(categories) * 10"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QzYnjzXBZXXt"
      },
      "source": [
        "# creating train test split\n",
        "x_train, x_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "print('Train set:', len(x_train))\n",
        "print('Test set:', len(x_test))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set: 195\nTest set: 49\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "18OZf2kfkVNB"
      },
      "source": [
        "## Feature Extraction using ORB\n",
        "\n",
        "The first step is to extract descriptors for each image in our dataset. We will use ORB to extract descriptors.\n",
        "\n",
        "*   Create ORB detector with 64 keypoints.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ptLbPcoow-ar"
      },
      "source": [
        "# solution\n",
        "orbExtractor = feature.ORB(n_keypoints=64)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3yinPkL8brow"
      },
      "source": [
        "*   Extract ORB descriptors from all the images in the train set.\n",
        "*   Note that, each patch would produce a descriptor of size (256,). So each image would return (N x 256) descriptors, where N is the number of keypoints."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 195/195 [00:41<00:00,  4.66it/s]\n"
          ]
        }
      ],
      "source": [
        "# solution\n",
        "x_trainOrb = []\n",
        "for imagePath in tqdm(x_train):\n",
        "    image = loadImage(imagePath, gray=True)\n",
        "    orbExtractor.detect_and_extract(image)\n",
        "    x_trainOrb.append(orbExtractor.descriptors)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XYo0GYeOxeHM"
      },
      "source": [
        "# solution\n",
        "print(\"number of images: \", len(x_trainOrb))\n",
        "print(\"shape of features extracted: \", x_trainOrb[0].shape)\n",
        "assert x_trainOrb[0].shape == (64, 256)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of images:  195\nshape of features extracted:  (64, 256)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "420YQkAzleTQ"
      },
      "source": [
        "## Codebook Construction\n",
        "\n",
        "Codewords are nothing but vector representation of similar patches. This codeword produces a codebook similar to a word dictionary. We will create the codebook using K-Means algorithm\n",
        "\n",
        "*   Create a codebook using K-Means with k=number_of_classes*10\n",
        "*   Hint: Use sklearn.cluster.MiniBatchKMeans for K-Means"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UJSBg-QCd--0"
      },
      "source": [
        "from sklearn.cluster import MiniBatchKMeans"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iO0e4718ppJt"
      },
      "source": [
        "# solution\n",
        "descriptors = np.vstack(x_trainOrb)\n",
        "clustering = MiniBatchKMeans(n_clusters=ncl)\n",
        "klabels = clustering.fit_predict(descriptors)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0GAD_JuNpqMt"
      },
      "source": [
        "*   Create a histogram using the cluster centers for each image descriptor.\n",
        "    *   Remember the histogram would be of size *n_images x n_clusters*.\n",
        "    *   Calculate the histogram and divide by the feature length to normalize"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SR0_9HnbDFBe",
        "tags": []
      },
      "source": [
        "# solution\n",
        "klabels_img = klabels.reshape(-1, 64)\n",
        "cluster_histograms = []\n",
        "for image_labels in klabels_img:\n",
        "    hist, _ = np.histogram(image_labels, bins=ncl)\n",
        "    hist = hist / image_labels.shape[0]\n",
        "    cluster_histograms.append(hist)\n",
        "dictionary = np.vstack(cluster_histograms)\n",
        "dictionary.shape"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(195, 30)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jmRO7dfLjgZa"
      },
      "source": [
        "\n",
        "# Creating Classification Model\n",
        "\n",
        "*   The next step is to create a classification model. We will use a C-Support Vector Classification for creating the model.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K7VTBz1Oimtz"
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import GridSearchCV"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IjFFpykV-GOI"
      },
      "source": [
        "# note the usage of grid search to select the best parameters\n",
        "\n",
        "gammas = np.logspace(-6, -1, 10)\n",
        "C = np.array([0.5, 1, 2, 4, 8, 10, 15, 20, 50, 100, 200, 375, 500, 1000])\n",
        "\n",
        "svc = SVC(decision_function_shape='ovr')\n",
        "\n",
        "clf = GridSearchCV(estimator=svc, param_grid=dict(gamma=gammas, C=C), n_jobs=-1)\n",
        "\n",
        "clf.fit(dictionary, y_train)\n",
        "\n",
        "print('Best accuracy:', clf.best_score_) \n",
        "print('The best value of gamma:', clf.best_estimator_.gamma)\n",
        "print('The best value of C:', clf.best_estimator_.C)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best accuracy: 0.4717948717948718\nThe best value of gamma: 0.02782559402207126\nThe best value of C: 200.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eqThTmO5j1-p"
      },
      "source": [
        "# Testing the Classification Model\n",
        "\n",
        "*   Extract descriptors using ORB for the test split\n",
        "*   Use the previously trained k-means to generate the histogram\n",
        "*   Use the classifier to predict the label\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gVl3FzQWgv54"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x2Gzbww9e0pP"
      },
      "source": [
        "# solution\n",
        "x_testOrb = []\n",
        "for imagePath in tqdm(x_test):\n",
        "    image = loadImage(imagePath, gray=True)\n",
        "    orbExtractor.detect_and_extract(image)\n",
        "    x_testOrb.append(orbExtractor.descriptors)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 49/49 [00:11<00:00,  4.38it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "testklabels = clustering.predict(np.vstack(x_testOrb))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(49, 64)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(49, 30)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "klabels_test_img = testklabels.reshape(-1, 64)\n",
        "print(klabels_test_img.shape)\n",
        "test_cluster_histograms = []\n",
        "for image_labels in klabels_test_img:\n",
        "    hist, _ = np.histogram(image_labels, bins=ncl)\n",
        "    hist = hist / image_labels.shape[0]\n",
        "    test_cluster_histograms.append(hist)\n",
        "testdictionary = np.vstack(test_cluster_histograms)\n",
        "testdictionary.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "predicted_labels = clf.predict(testdictionary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(49,)\n(49,)\n"
          ]
        }
      ],
      "source": [
        "print(predicted_labels.shape)\n",
        "print(y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gGyQUtU3lAEz"
      },
      "source": [
        "*   Calculate the accuracy score for the classification model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PszxSB0Ek_Lt"
      },
      "source": [
        "# solution\n",
        "print(confusion_matrix(predicted_labels, y_test))\n",
        "print(f\"Classification accuracy: {100*accuracy_score(predicted_labels, y_test):.2f}%\")\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[12  5  2]\n [ 7 10  8]\n [ 0  3  2]]\nClassification accuracy: 48.98%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7TN4rRra9yv_"
      },
      "source": [
        "*   Why do we use Clustering to create the codebook? \n",
        "*   What are the other techniques that can be used to create the codebook?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ri9kU3wa3Rei"
      },
      "source": [
        "**Solution**\n",
        "\n",
        "*(Double-click or enter to edit)*\n",
        "\n",
        "..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K-8E3dBw8Zoa"
      },
      "source": [
        "# Extracting features from Deep Network\n",
        "\n",
        "It is quite possible to extract features (similar to SIFT or ORB) from different layers of deep network.\n",
        "\n",
        "*   Load ResNet50 model with imagenet weights and check the summary of the model\n",
        "*   Create a model to extract features from the 'avg_pool' layer.\n",
        "*   Extract features from the layer for all the train images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xbDjklM3l0uq"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras import Model"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "89QGrzE5l7gu",
        "tags": []
      },
      "source": [
        "# solution\n",
        "feat_extraction_model = ResNet50(weights='imagenet', include_top=False)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EJ83bPO3mO16",
        "tags": []
      },
      "source": [
        "# solution\n",
        "resNetFeats = []\n",
        "numFeatures = []\n",
        "for imagePath in x_train:\n",
        "    image = loadImage(imagePath)\n",
        "    if len(image.shape) == 2:\n",
        "        # convert to rgb (replicate if the image is grayscale)\n",
        "        image = np.moveaxis(np.array([image, image, image]), [0, 1, 2], [2, 0, 1])\n",
        "    output = feat_extraction_model(image[np.newaxis, :])\n",
        "    output = output.numpy().reshape(-1, output.shape[-1])\n",
        "    resNetFeats.append(output)\n",
        "    numFeatures.append(output.shape[0])"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GkEprqtK87q2"
      },
      "source": [
        "*   Create codebook using the extracted features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5crz4gBz9CQF"
      },
      "source": [
        "# solution\n",
        "stackedResNetFeats = np.vstack(resNetFeats)\n",
        "cumNumFeatures = np.cumsum(numFeatures).astype(np.int)\n",
        "print(stackedResNetFeats.shape)\n",
        "print(cumNumFeatures[0], cumNumFeatures[-1], len(cumNumFeatures))"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(15610, 2048)\n90 15610 195\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4cD28JWOFm2w"
      },
      "source": [
        "# solution\n",
        "clusteringResNetFeats = MiniBatchKMeans(n_clusters=ncl)\n",
        "resnetkLabels = clusteringResNetFeats.fit_predict(stackedResNetFeats)"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bjax5E3gFxiF"
      },
      "source": [
        "# solution\n",
        "cluster_histograms = []\n",
        "for idx in range(len(cumNumFeatures)):\n",
        "    end_idx = cumNumFeatures[idx]\n",
        "    start_idx = 0 if idx == 0 else cumNumFeatures[idx - 1]\n",
        "\n",
        "    image_labels = resnetkLabels[start_idx:end_idx]\n",
        "    # print(start_idx, end_idx, image_labels.shape)\n",
        "    hist, _ = np.histogram(resnetkLabels[start_idx:end_idx], bins=ncl)\n",
        "    hist = hist / image_labels.shape[0]\n",
        "    cluster_histograms.append(hist)\n",
        "dictionary = np.vstack(cluster_histograms)\n",
        "dictionary.shape\n"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 90 (90,)\n90 160 (70,)\n160 240 (80,)\n240 310 (70,)\n310 390 (80,)\n390 460 (70,)\n460 550 (90,)\n550 630 (80,)\n630 700 (70,)\n700 770 (70,)\n770 850 (80,)\n850 950 (100,)\n950 1040 (90,)\n1040 1130 (90,)\n1130 1220 (90,)\n1220 1300 (80,)\n1300 1370 (70,)\n1370 1440 (70,)\n1440 1510 (70,)\n1510 1580 (70,)\n1580 1650 (70,)\n1650 1730 (80,)\n1730 1790 (60,)\n1790 1860 (70,)\n1860 1950 (90,)\n1950 2020 (70,)\n2020 2110 (90,)\n2110 2210 (100,)\n2210 2300 (90,)\n2300 2390 (90,)\n2390 2460 (70,)\n2460 2530 (70,)\n2530 2610 (80,)\n2610 2670 (60,)\n2670 2750 (80,)\n2750 2830 (80,)\n2830 2910 (80,)\n2910 2980 (70,)\n2980 3060 (80,)\n3060 3140 (80,)\n3140 3230 (90,)\n3230 3300 (70,)\n3300 3380 (80,)\n3380 3460 (80,)\n3460 3530 (70,)\n3530 3620 (90,)\n3620 3690 (70,)\n3690 3780 (90,)\n3780 3850 (70,)\n3850 3950 (100,)\n3950 4050 (100,)\n4050 4140 (90,)\n4140 4230 (90,)\n4230 4300 (70,)\n4300 4380 (80,)\n4380 4480 (100,)\n4480 4540 (60,)\n4540 4610 (70,)\n4610 4690 (80,)\n4690 4770 (80,)\n4770 4870 (100,)\n4870 4950 (80,)\n4950 5020 (70,)\n5020 5100 (80,)\n5100 5200 (100,)\n5200 5290 (90,)\n5290 5360 (70,)\n5360 5450 (90,)\n5450 5510 (60,)\n5510 5590 (80,)\n5590 5660 (70,)\n5660 5740 (80,)\n5740 5840 (100,)\n5840 5920 (80,)\n5920 6000 (80,)\n6000 6080 (80,)\n6080 6170 (90,)\n6170 6270 (100,)\n6270 6350 (80,)\n6350 6440 (90,)\n6440 6530 (90,)\n6530 6600 (70,)\n6600 6670 (70,)\n6670 6750 (80,)\n6750 6820 (70,)\n6820 6880 (60,)\n6880 6970 (90,)\n6970 7060 (90,)\n7060 7130 (70,)\n7130 7220 (90,)\n7220 7300 (80,)\n7300 7370 (70,)\n7370 7460 (90,)\n7460 7530 (70,)\n7530 7590 (60,)\n7590 7670 (80,)\n7670 7750 (80,)\n7750 7820 (70,)\n7820 7900 (80,)\n7900 8000 (100,)\n8000 8080 (80,)\n8080 8170 (90,)\n8170 8240 (70,)\n8240 8300 (60,)\n8300 8380 (80,)\n8380 8450 (70,)\n8450 8550 (100,)\n8550 8630 (80,)\n8630 8700 (70,)\n8700 8800 (100,)\n8800 8880 (80,)\n8880 8970 (90,)\n8970 9040 (70,)\n9040 9120 (80,)\n9120 9210 (90,)\n9210 9280 (70,)\n9280 9360 (80,)\n9360 9450 (90,)\n9450 9540 (90,)\n9540 9630 (90,)\n9630 9700 (70,)\n9700 9790 (90,)\n9790 9870 (80,)\n9870 9950 (80,)\n9950 10040 (90,)\n10040 10140 (100,)\n10140 10230 (90,)\n10230 10320 (90,)\n10320 10410 (90,)\n10410 10490 (80,)\n10490 10570 (80,)\n10570 10640 (70,)\n10640 10740 (100,)\n10740 10820 (80,)\n10820 10920 (100,)\n10920 10990 (70,)\n10990 11080 (90,)\n11080 11150 (70,)\n11150 11230 (80,)\n11230 11300 (70,)\n11300 11360 (60,)\n11360 11430 (70,)\n11430 11520 (90,)\n11520 11600 (80,)\n11600 11680 (80,)\n11680 11750 (70,)\n11750 11840 (90,)\n11840 11920 (80,)\n11920 11990 (70,)\n11990 12070 (80,)\n12070 12160 (90,)\n12160 12240 (80,)\n12240 12330 (90,)\n12330 12420 (90,)\n12420 12510 (90,)\n12510 12580 (70,)\n12580 12650 (70,)\n12650 12720 (70,)\n12720 12790 (70,)\n12790 12850 (60,)\n12850 12930 (80,)\n12930 13000 (70,)\n13000 13060 (60,)\n13060 13120 (60,)\n13120 13190 (70,)\n13190 13280 (90,)\n13280 13360 (80,)\n13360 13460 (100,)\n13460 13550 (90,)\n13550 13640 (90,)\n13640 13720 (80,)\n13720 13810 (90,)\n13810 13890 (80,)\n13890 13990 (100,)\n13990 14070 (80,)\n14070 14160 (90,)\n14160 14220 (60,)\n14220 14300 (80,)\n14300 14360 (60,)\n14360 14420 (60,)\n14420 14500 (80,)\n14500 14560 (60,)\n14560 14660 (100,)\n14660 14730 (70,)\n14730 14810 (80,)\n14810 14900 (90,)\n14900 14960 (60,)\n14960 15050 (90,)\n15050 15140 (90,)\n15140 15210 (70,)\n15210 15270 (60,)\n15270 15370 (100,)\n15370 15440 (70,)\n15440 15520 (80,)\n15520 15610 (90,)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(195, 30)"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K_RB2vPl9CzB"
      },
      "source": [
        "*   Train SVM classifier using the codebook"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5oKk_Wzz9HLf"
      },
      "source": [
        "gammas = np.logspace(-6, -1, 10)\n",
        "C = np.array([0.5, 1, 2, 4, 8, 10, 15, 20, 50, 100, 200, 375, 500, 1000])\n",
        "\n",
        "svc = SVC(decision_function_shape='ovr')\n",
        "\n",
        "clf = GridSearchCV(estimator=svc, param_grid=dict(gamma=gammas, C=C), n_jobs=-1)\n",
        "\n",
        "clf.fit(dictionary, y_train)\n",
        "\n",
        "print('Best accuracy:', clf.best_score_) \n",
        "print('The best value of gamma:', clf.best_estimator_.gamma)\n",
        "print('The best value of C:', clf.best_estimator_.C)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best accuracy: 0.8666666666666668\nThe best value of gamma: 0.1\nThe best value of C: 1000.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ym0XesGL9Hrc"
      },
      "source": [
        "*   Evaluate the test set using the above method"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NM6LIynq9Ma1"
      },
      "source": [
        "# solution\n",
        "testResNetFeatures = []\n",
        "testNumFeatures = []\n",
        "for imagePath in x_test:\n",
        "    image = loadImage(imagePath)\n",
        "    if len(image.shape) == 2:\n",
        "        # convert to rgb (replicate if the image is grayscale)\n",
        "        image = np.moveaxis(np.array([image, image, image]), [0, 1, 2], [2, 0, 1])\n",
        "    output = feat_extraction_model(image[np.newaxis, :])\n",
        "    output = output.numpy().reshape(-1, output.shape[-1])\n",
        "    testResNetFeatures.append(output)\n",
        "    testNumFeatures.append(output.shape[0])"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4040, 2048)\n80 4040 49\n"
          ]
        }
      ],
      "source": [
        "testStackedResNetFeats = np.vstack(testResNetFeatures)\n",
        "testCumNumFeatures = np.cumsum(testNumFeatures).astype(np.int)\n",
        "print(testStackedResNetFeats.shape)\n",
        "print(testCumNumFeatures[0], testCumNumFeatures[-1], len(testCumNumFeatures))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {},
      "outputs": [],
      "source": [
        "testResnetkLabels = clusteringResNetFeats.predict(testStackedResNetFeats)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "testHistograms = []\n",
        "for idx in range(len(testCumNumFeatures)):\n",
        "    end_idx = testCumNumFeatures[idx]\n",
        "    start_idx = 0 if idx == 0 else testCumNumFeatures[idx - 1]\n",
        "    image_labels = testResnetkLabels[start_idx:end_idx]\n",
        "    hist, _ = np.histogram(image_labels, bins=ncl)\n",
        "    hist = hist / image_labels.shape[0]\n",
        "    cluster_histograms.append(hist)\n",
        "dictionary = np.vstack(cluster_histograms)\n",
        "dictionary.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d-OnKf-ti_vy"
      },
      "source": [
        "*   Calculate the accuracy score for the classification model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "upqdRQUoGC94"
      },
      "source": [
        "# solution\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DjL0oQCumkrV"
      },
      "source": [
        "## t-distributed Stochastic Neighbor Embedding.\n",
        "\n",
        "In order to visualize the features of a higher dimension data, t-SNE is used. t-SNE converts the affinities of the data points to probabilities. It recreates the probability distribution in a low-dimensional space. It is very helpful in visualizing features of different layers in a neural network.\n",
        "\n",
        "You can find more information about t-SNE [here](https://scikit-learn.org/stable/modules/manifold.html#t-distributed-stochastic-neighbor-embedding-t-sne)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ahIG1fulhW9"
      },
      "source": [
        "from sklearn.manifold import TSNE\n",
        "\n",
        "model = TSNE(n_components=2, random_state=0)\n",
        "\n",
        "np.set_printoptions(suppress=True)\n",
        "\n",
        "low_embedding = model.fit_transform(dictionary) \n",
        "\n",
        "plt.figure(figsize=(20,10))\n",
        "plt.scatter(low_embedding[:, 0], low_embedding[:, 1], c=y_train)\n",
        "plt.title(\"TSNE visualization\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3_HR5GjFpjik"
      },
      "source": [
        "*   What do you infer from the t-SNE plot?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ueY9rvGBrVIc"
      },
      "source": [
        "**Solution**\n",
        "\n",
        "*(Double-click or enter to edit)*\n",
        "\n",
        "..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eafGx0Hv9M6p"
      },
      "source": [
        "*   Compare the performance of both the BoVW models. Which model works better and why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U9SOuiKwiXkr"
      },
      "source": [
        "**Solution**\n",
        "\n",
        "*(Double-click or enter to edit)*\n",
        "\n",
        "..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8BuiFGxPjDb1"
      },
      "source": [
        "*   Can the performance of pre-trained model increased further? If so, how?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0kuJnOb9jE9r"
      },
      "source": [
        "**Solution**\n",
        "\n",
        "*(Double-click or enter to edit)*\n",
        "\n",
        "..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NnN_t5Me7N5O"
      },
      "source": [
        "\n",
        "---\n",
        "\n",
        "## **End of P7: Image Classification using Bag of Visual Words**\n",
        "Deadline for P7 submission in CampusVirtual is: **Thursday, the 26th of November, 2020**"
      ]
    }
  ]
}